{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QWdlURYAKgGl"
   },
   "source": [
    "Data processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 8765,
     "status": "ok",
     "timestamp": 1620393078545,
     "user": {
      "displayName": "Kevin Nguyen",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjO7Ro_1aXKh2v0yIWTJtWbDipOcwKLlP1iD8Rl=s64",
      "userId": "12975752177220403005"
     },
     "user_tz": 240
    },
    "id": "5OnoelI_zB3A",
    "outputId": "8ba23114-c8ad-4010-b595-270733063dd0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in c:\\users\\nango\\anaconda3\\lib\\site-packages (4.5.0)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\nango\\anaconda3\\lib\\site-packages (from transformers) (1.19.5)\n",
      "Requirement already satisfied: sacremoses in c:\\users\\nango\\anaconda3\\lib\\site-packages (from transformers) (0.0.43)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\nango\\anaconda3\\lib\\site-packages (from transformers) (2021.4.4)\n",
      "Requirement already satisfied: requests in c:\\users\\nango\\anaconda3\\lib\\site-packages (from transformers) (2.24.0)\n",
      "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in c:\\users\\nango\\anaconda3\\lib\\site-packages (from transformers) (1.7.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\nango\\anaconda3\\lib\\site-packages (from transformers) (20.1)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\nango\\anaconda3\\lib\\site-packages (from transformers) (4.42.1)\n",
      "Requirement already satisfied: tokenizers<0.11,>=0.10.1 in c:\\users\\nango\\anaconda3\\lib\\site-packages (from transformers) (0.10.1)\n",
      "Requirement already satisfied: filelock in c:\\users\\nango\\anaconda3\\lib\\site-packages (from transformers) (3.0.12)\n",
      "Requirement already satisfied: joblib in c:\\users\\nango\\anaconda3\\lib\\site-packages (from sacremoses->transformers) (0.14.1)\n",
      "Requirement already satisfied: click in c:\\users\\nango\\anaconda3\\lib\\site-packages (from sacremoses->transformers) (7.1.2)\n",
      "Requirement already satisfied: six in c:\\users\\nango\\anaconda3\\lib\\site-packages (from sacremoses->transformers) (1.15.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\nango\\anaconda3\\lib\\site-packages (from requests->transformers) (2019.11.28)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in c:\\users\\nango\\anaconda3\\lib\\site-packages (from requests->transformers) (1.25.9)\n",
      "Requirement already satisfied: idna<3,>=2.5 in c:\\users\\nango\\anaconda3\\lib\\site-packages (from requests->transformers) (2.10)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in c:\\users\\nango\\anaconda3\\lib\\site-packages (from requests->transformers) (3.0.4)\n",
      "Requirement already satisfied: zipp>=0.5 in c:\\users\\nango\\anaconda3\\lib\\site-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (2.2.0)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in c:\\users\\nango\\anaconda3\\lib\\site-packages (from packaging->transformers) (2.4.6)\n",
      "Requirement already satisfied: tensorflow==2.4.1 in c:\\users\\nango\\appdata\\roaming\\python\\python37\\site-packages (2.4.1)\n",
      "Requirement already satisfied: google-pasta~=0.2 in c:\\users\\nango\\anaconda3\\lib\\site-packages (from tensorflow==2.4.1) (0.2.0)\n",
      "Requirement already satisfied: termcolor~=1.1.0 in c:\\users\\nango\\anaconda3\\lib\\site-packages (from tensorflow==2.4.1) (1.1.0)\n",
      "Requirement already satisfied: grpcio~=1.32.0 in c:\\users\\nango\\anaconda3\\lib\\site-packages (from tensorflow==2.4.1) (1.32.0)\n",
      "Requirement already satisfied: wheel~=0.35 in c:\\users\\nango\\anaconda3\\lib\\site-packages (from tensorflow==2.4.1) (0.36.2)\n",
      "Requirement already satisfied: numpy~=1.19.2 in c:\\users\\nango\\anaconda3\\lib\\site-packages (from tensorflow==2.4.1) (1.19.5)\n",
      "Requirement already satisfied: keras-preprocessing~=1.1.2 in c:\\users\\nango\\anaconda3\\lib\\site-packages (from tensorflow==2.4.1) (1.1.2)\n",
      "Requirement already satisfied: h5py~=2.10.0 in c:\\users\\nango\\anaconda3\\lib\\site-packages (from tensorflow==2.4.1) (2.10.0)\n",
      "Requirement already satisfied: tensorboard~=2.4 in c:\\users\\nango\\appdata\\roaming\\python\\python37\\site-packages (from tensorflow==2.4.1) (2.5.0)\n",
      "Requirement already satisfied: typing-extensions~=3.7.4 in c:\\users\\nango\\anaconda3\\lib\\site-packages (from tensorflow==2.4.1) (3.7.4.3)\n",
      "Requirement already satisfied: tensorflow-estimator<2.5.0,>=2.4.0 in c:\\users\\nango\\appdata\\roaming\\python\\python37\\site-packages (from tensorflow==2.4.1) (2.4.0)\n",
      "Requirement already satisfied: absl-py~=0.10 in c:\\users\\nango\\anaconda3\\lib\\site-packages (from tensorflow==2.4.1) (0.11.0)\n",
      "Requirement already satisfied: protobuf>=3.9.2 in c:\\users\\nango\\anaconda3\\lib\\site-packages (from tensorflow==2.4.1) (3.12.2)\n",
      "Requirement already satisfied: gast==0.3.3 in c:\\users\\nango\\appdata\\roaming\\python\\python37\\site-packages (from tensorflow==2.4.1) (0.3.3)\n",
      "Requirement already satisfied: six~=1.15.0 in c:\\users\\nango\\anaconda3\\lib\\site-packages (from tensorflow==2.4.1) (1.15.0)\n",
      "Requirement already satisfied: astunparse~=1.6.3 in c:\\users\\nango\\anaconda3\\lib\\site-packages (from tensorflow==2.4.1) (1.6.3)\n",
      "Requirement already satisfied: opt-einsum~=3.3.0 in c:\\users\\nango\\anaconda3\\lib\\site-packages (from tensorflow==2.4.1) (3.3.0)\n",
      "Requirement already satisfied: wrapt~=1.12.1 in c:\\users\\nango\\anaconda3\\lib\\site-packages (from tensorflow==2.4.1) (1.12.1)\n",
      "Requirement already satisfied: flatbuffers~=1.12.0 in c:\\users\\nango\\anaconda3\\lib\\site-packages (from tensorflow==2.4.1) (1.12)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in c:\\users\\nango\\anaconda3\\lib\\site-packages (from tensorboard~=2.4->tensorflow==2.4.1) (1.8.0)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\nango\\anaconda3\\lib\\site-packages (from tensorboard~=2.4->tensorflow==2.4.1) (2.24.0)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in c:\\users\\nango\\anaconda3\\lib\\site-packages (from tensorboard~=2.4->tensorflow==2.4.1) (1.0.0)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in c:\\users\\nango\\anaconda3\\lib\\site-packages (from tensorboard~=2.4->tensorflow==2.4.1) (0.4.4)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\nango\\anaconda3\\lib\\site-packages (from tensorboard~=2.4->tensorflow==2.4.1) (3.3.3)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in c:\\users\\nango\\anaconda3\\lib\\site-packages (from tensorboard~=2.4->tensorflow==2.4.1) (45.2.0.post20200210)\n",
      "Requirement already satisfied: google-auth<2,>=1.6.3 in c:\\users\\nango\\anaconda3\\lib\\site-packages (from tensorboard~=2.4->tensorflow==2.4.1) (1.20.1)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in c:\\users\\nango\\appdata\\roaming\\python\\python37\\site-packages (from tensorboard~=2.4->tensorflow==2.4.1) (0.6.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\nango\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow==2.4.1) (2019.11.28)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in c:\\users\\nango\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow==2.4.1) (3.0.4)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in c:\\users\\nango\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow==2.4.1) (1.25.9)\n",
      "Requirement already satisfied: idna<3,>=2.5 in c:\\users\\nango\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow==2.4.1) (2.10)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in c:\\users\\nango\\anaconda3\\lib\\site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.4->tensorflow==2.4.1) (1.3.0)\n",
      "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in c:\\users\\nango\\anaconda3\\lib\\site-packages (from markdown>=2.6.8->tensorboard~=2.4->tensorflow==2.4.1) (1.7.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3.5\" in c:\\users\\nango\\anaconda3\\lib\\site-packages (from google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow==2.4.1) (4.6)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\nango\\anaconda3\\lib\\site-packages (from google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow==2.4.1) (0.2.8)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in c:\\users\\nango\\anaconda3\\lib\\site-packages (from google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow==2.4.1) (4.1.1)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in c:\\users\\nango\\anaconda3\\lib\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.4->tensorflow==2.4.1) (3.1.0)\n",
      "Requirement already satisfied: zipp>=0.5 in c:\\users\\nango\\anaconda3\\lib\\site-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard~=2.4->tensorflow==2.4.1) (2.2.0)\n",
      "Requirement already satisfied: pyasn1>=0.1.3 in c:\\users\\nango\\anaconda3\\lib\\site-packages (from rsa<5,>=3.1.4; python_version >= \"3.5\"->google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow==2.4.1) (0.4.8)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: sklearn in c:\\users\\nango\\anaconda3\\lib\\site-packages (0.0)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\nango\\anaconda3\\lib\\site-packages (from sklearn) (0.23.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\nango\\anaconda3\\lib\\site-packages (from scikit-learn->sklearn) (2.1.0)\n",
      "Requirement already satisfied: numpy>=1.13.3 in c:\\users\\nango\\anaconda3\\lib\\site-packages (from scikit-learn->sklearn) (1.19.5)\n",
      "Requirement already satisfied: scipy>=0.19.1 in c:\\users\\nango\\anaconda3\\lib\\site-packages (from scikit-learn->sklearn) (1.4.1)\n",
      "Requirement already satisfied: joblib>=0.11 in c:\\users\\nango\\anaconda3\\lib\\site-packages (from scikit-learn->sklearn) (0.14.1)\n",
      "Requirement already satisfied: keras in c:\\users\\nango\\anaconda3\\lib\\site-packages (2.0.0)\n",
      "Requirement already satisfied: pyyaml in c:\\users\\nango\\anaconda3\\lib\\site-packages (from keras) (5.3)\n",
      "Requirement already satisfied: six in c:\\users\\nango\\anaconda3\\lib\\site-packages (from keras) (1.15.0)\n",
      "Requirement already satisfied: tensorflow in c:\\users\\nango\\appdata\\roaming\\python\\python37\\site-packages (from keras) (2.4.1)\n",
      "Requirement already satisfied: tensorboard~=2.4 in c:\\users\\nango\\appdata\\roaming\\python\\python37\\site-packages (from tensorflow->keras) (2.5.0)\n",
      "Requirement already satisfied: google-pasta~=0.2 in c:\\users\\nango\\anaconda3\\lib\\site-packages (from tensorflow->keras) (0.2.0)\n",
      "Requirement already satisfied: flatbuffers~=1.12.0 in c:\\users\\nango\\anaconda3\\lib\\site-packages (from tensorflow->keras) (1.12)\n",
      "Requirement already satisfied: typing-extensions~=3.7.4 in c:\\users\\nango\\anaconda3\\lib\\site-packages (from tensorflow->keras) (3.7.4.3)\n",
      "Requirement already satisfied: protobuf>=3.9.2 in c:\\users\\nango\\anaconda3\\lib\\site-packages (from tensorflow->keras) (3.12.2)\n",
      "Requirement already satisfied: gast==0.3.3 in c:\\users\\nango\\appdata\\roaming\\python\\python37\\site-packages (from tensorflow->keras) (0.3.3)\n",
      "Requirement already satisfied: opt-einsum~=3.3.0 in c:\\users\\nango\\anaconda3\\lib\\site-packages (from tensorflow->keras) (3.3.0)\n",
      "Requirement already satisfied: termcolor~=1.1.0 in c:\\users\\nango\\anaconda3\\lib\\site-packages (from tensorflow->keras) (1.1.0)\n",
      "Requirement already satisfied: wheel~=0.35 in c:\\users\\nango\\anaconda3\\lib\\site-packages (from tensorflow->keras) (0.36.2)\n",
      "Requirement already satisfied: tensorflow-estimator<2.5.0,>=2.4.0 in c:\\users\\nango\\appdata\\roaming\\python\\python37\\site-packages (from tensorflow->keras) (2.4.0)\n",
      "Requirement already satisfied: grpcio~=1.32.0 in c:\\users\\nango\\anaconda3\\lib\\site-packages (from tensorflow->keras) (1.32.0)\n",
      "Requirement already satisfied: wrapt~=1.12.1 in c:\\users\\nango\\anaconda3\\lib\\site-packages (from tensorflow->keras) (1.12.1)\n",
      "Requirement already satisfied: keras-preprocessing~=1.1.2 in c:\\users\\nango\\anaconda3\\lib\\site-packages (from tensorflow->keras) (1.1.2)\n",
      "Requirement already satisfied: absl-py~=0.10 in c:\\users\\nango\\anaconda3\\lib\\site-packages (from tensorflow->keras) (0.11.0)\n",
      "Requirement already satisfied: astunparse~=1.6.3 in c:\\users\\nango\\anaconda3\\lib\\site-packages (from tensorflow->keras) (1.6.3)\n",
      "Requirement already satisfied: numpy~=1.19.2 in c:\\users\\nango\\anaconda3\\lib\\site-packages (from tensorflow->keras) (1.19.5)\n",
      "Requirement already satisfied: h5py~=2.10.0 in c:\\users\\nango\\anaconda3\\lib\\site-packages (from tensorflow->keras) (2.10.0)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in c:\\users\\nango\\anaconda3\\lib\\site-packages (from tensorboard~=2.4->tensorflow->keras) (1.8.0)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in c:\\users\\nango\\anaconda3\\lib\\site-packages (from tensorboard~=2.4->tensorflow->keras) (45.2.0.post20200210)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in c:\\users\\nango\\anaconda3\\lib\\site-packages (from tensorboard~=2.4->tensorflow->keras) (0.4.4)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\nango\\anaconda3\\lib\\site-packages (from tensorboard~=2.4->tensorflow->keras) (3.3.3)\n",
      "Requirement already satisfied: google-auth<2,>=1.6.3 in c:\\users\\nango\\anaconda3\\lib\\site-packages (from tensorboard~=2.4->tensorflow->keras) (1.20.1)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in c:\\users\\nango\\appdata\\roaming\\python\\python37\\site-packages (from tensorboard~=2.4->tensorflow->keras) (0.6.1)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in c:\\users\\nango\\anaconda3\\lib\\site-packages (from tensorboard~=2.4->tensorflow->keras) (1.0.0)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\nango\\anaconda3\\lib\\site-packages (from tensorboard~=2.4->tensorflow->keras) (2.24.0)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in c:\\users\\nango\\anaconda3\\lib\\site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.4->tensorflow->keras) (1.3.0)\n",
      "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in c:\\users\\nango\\anaconda3\\lib\\site-packages (from markdown>=2.6.8->tensorboard~=2.4->tensorflow->keras) (1.7.0)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\nango\\anaconda3\\lib\\site-packages (from google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow->keras) (0.2.8)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3.5\" in c:\\users\\nango\\anaconda3\\lib\\site-packages (from google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow->keras) (4.6)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in c:\\users\\nango\\anaconda3\\lib\\site-packages (from google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow->keras) (4.1.1)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in c:\\users\\nango\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow->keras) (3.0.4)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in c:\\users\\nango\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow->keras) (1.25.9)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\nango\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow->keras) (2019.11.28)\n",
      "Requirement already satisfied: idna<3,>=2.5 in c:\\users\\nango\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow->keras) (2.10)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in c:\\users\\nango\\anaconda3\\lib\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.4->tensorflow->keras) (3.1.0)\n",
      "Requirement already satisfied: zipp>=0.5 in c:\\users\\nango\\anaconda3\\lib\\site-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard~=2.4->tensorflow->keras) (2.2.0)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in c:\\users\\nango\\anaconda3\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow->keras) (0.4.8)\n"
     ]
    }
   ],
   "source": [
    "!pip install --user transformers\n",
    "!pip install --user tensorflow==2.4.1\n",
    "!pip install --user sklearn\n",
    "!pip install --user keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "executionInfo": {
     "elapsed": 3235,
     "status": "ok",
     "timestamp": 1620393081508,
     "user": {
      "displayName": "Kevin Nguyen",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjO7Ro_1aXKh2v0yIWTJtWbDipOcwKLlP1iD8Rl=s64",
      "userId": "12975752177220403005"
     },
     "user_tz": 240
    },
    "id": "H31UD81GKbGr"
   },
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "Traceback (most recent call last):\n  File \"C:\\Users\\nango\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py\", line 64, in <module>\n    from tensorflow.python._pywrap_tensorflow_internal import *\nImportError: DLL load failed: A dynamic link library (DLL) initialization routine failed.\n\n\nFailed to load the native TensorFlow runtime.\n\nSee https://www.tensorflow.org/install/errors\n\nfor some common reasons and solutions.  Include the entire stack trace\nabove this error message when asking for help.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     63\u001b[0m   \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 64\u001b[1;33m     \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_pywrap_tensorflow_internal\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[1;33m*\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     65\u001b[0m   \u001b[1;31m# This try catch logic is because there is no bazel equivalent for py_extension.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mImportError\u001b[0m: DLL load failed: A dynamic link library (DLL) initialization routine failed.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-7e785e2a13ff>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mast\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtransformers\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mBertTokenizerFast\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mTFBertModel\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel_selection\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\transformers\\__init__.py\u001b[0m in \u001b[0;36m__getattr__\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m   2485\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"__version__\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2486\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0m__version__\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2487\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__getattr__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2488\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2489\u001b[0m     \u001b[0msys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodules\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0m__name__\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_LazyModule\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m__name__\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_import_structure\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\transformers\\file_utils.py\u001b[0m in \u001b[0;36m__getattr__\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m   1698\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_class_to_module\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1699\u001b[0m             \u001b[0mmodule\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_module\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_class_to_module\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1700\u001b[1;33m             \u001b[0mvalue\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodule\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1701\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1702\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"module {self.__name__} has no attribute {name}\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\transformers\\file_utils.py\u001b[0m in \u001b[0;36m__getattr__\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m   1697\u001b[0m             \u001b[0mvalue\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_module\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1698\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_class_to_module\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1699\u001b[1;33m             \u001b[0mmodule\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_module\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_class_to_module\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1700\u001b[0m             \u001b[0mvalue\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodule\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1701\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\transformers\\models\\bert\\__init__.py\u001b[0m in \u001b[0;36m_get_module\u001b[1;34m(self, module_name)\u001b[0m\n\u001b[0;32m    151\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    152\u001b[0m         \u001b[1;32mdef\u001b[0m \u001b[0m_get_module\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodule_name\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 153\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mimportlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimport_module\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\".\"\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mmodule_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    154\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    155\u001b[0m     \u001b[0msys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodules\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0m__name__\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_LazyModule\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m__name__\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_import_structure\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\importlib\\__init__.py\u001b[0m in \u001b[0;36mimport_module\u001b[1;34m(name, package)\u001b[0m\n\u001b[0;32m    125\u001b[0m                 \u001b[1;32mbreak\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    126\u001b[0m             \u001b[0mlevel\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 127\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_bootstrap\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_gcd_import\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mlevel\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpackage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    128\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    129\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\transformers\\models\\bert\\modeling_tf_bert.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 24\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     25\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m...\u001b[0m\u001b[0mactivations_tf\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mget_tf_activation\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     39\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0msys\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0m_sys\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     40\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 41\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtools\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmodule_util\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0m_module_util\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     42\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutil\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlazy_loader\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mLazyLoader\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0m_LazyLoader\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     43\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     37\u001b[0m \u001b[1;31m# go/tf-wildcard-import\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     38\u001b[0m \u001b[1;31m# pylint: disable=wildcard-import,g-bad-import-order,g-import-not-at-top\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 39\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpywrap_tensorflow\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0m_pywrap_tensorflow\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     40\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     41\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0meager\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mcontext\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     81\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0msome\u001b[0m \u001b[0mcommon\u001b[0m \u001b[0mreasons\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0msolutions\u001b[0m\u001b[1;33m.\u001b[0m  \u001b[0mInclude\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mentire\u001b[0m \u001b[0mstack\u001b[0m \u001b[0mtrace\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     82\u001b[0m above this error message when asking for help.\"\"\" % traceback.format_exc()\n\u001b[1;32m---> 83\u001b[1;33m   \u001b[1;32mraise\u001b[0m \u001b[0mImportError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     84\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     85\u001b[0m \u001b[1;31m# pylint: enable=wildcard-import,g-import-not-at-top,unused-import,line-too-long\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mImportError\u001b[0m: Traceback (most recent call last):\n  File \"C:\\Users\\nango\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py\", line 64, in <module>\n    from tensorflow.python._pywrap_tensorflow_internal import *\nImportError: DLL load failed: A dynamic link library (DLL) initialization routine failed.\n\n\nFailed to load the native TensorFlow runtime.\n\nSee https://www.tensorflow.org/install/errors\n\nfor some common reasons and solutions.  Include the entire stack trace\nabove this error message when asking for help."
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import ast\n",
    "from transformers import BertTokenizerFast,TFBertModel\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from keras.models import Model\n",
    "from keras.callbacks import EarlyStopping,ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipfile\n",
    "with zipfile.ZipFile(\"spanbert_hf_base.zip\",\"r\") as zip_ref:\n",
    "    zip_ref.extractall()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "executionInfo": {
     "elapsed": 623,
     "status": "ok",
     "timestamp": 1620393081508,
     "user": {
      "displayName": "Kevin Nguyen",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjO7Ro_1aXKh2v0yIWTJtWbDipOcwKLlP1iD8Rl=s64",
      "userId": "12975752177220403005"
     },
     "user_tz": 240
    },
    "id": "8LgEBTaVRODg"
   },
   "outputs": [],
   "source": [
    "max_len=400\n",
    "doc_max_len=400"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "executionInfo": {
     "elapsed": 1084,
     "status": "ok",
     "timestamp": 1620393084227,
     "user": {
      "displayName": "Kevin Nguyen",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjO7Ro_1aXKh2v0yIWTJtWbDipOcwKLlP1iD8Rl=s64",
      "userId": "12975752177220403005"
     },
     "user_tz": 240
    },
    "id": "rHYRFcUaKjeU"
   },
   "outputs": [],
   "source": [
    "train_data=pd.read_csv(\"https://raw.githubusercontent.com/ipavlopoulos/toxic_spans/master/data/tsd_train.csv\")\n",
    "test_data=pd.read_csv(\"https://raw.githubusercontent.com/ipavlopoulos/toxic_spans/master/data/tsd_test.csv\")\n",
    "train, validation = train_test_split(train_data, test_size = 0.1,random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "executionInfo": {
     "elapsed": 682,
     "status": "ok",
     "timestamp": 1620393085499,
     "user": {
      "displayName": "Kevin Nguyen",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjO7Ro_1aXKh2v0yIWTJtWbDipOcwKLlP1iD8Rl=s64",
      "userId": "12975752177220403005"
     },
     "user_tz": 240
    },
    "id": "tmDZnD6Y0_bN"
   },
   "outputs": [],
   "source": [
    "def process_df(df):\n",
    "    df.spans=df.spans.apply(lambda x: ast.literal_eval(x))\n",
    "    df[\"sentiment\"]=df.spans.apply(lambda x: \"Negative\" if len(x)>0 else \"Neutral\")\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1324,
     "status": "ok",
     "timestamp": 1620393087400,
     "user": {
      "displayName": "Kevin Nguyen",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjO7Ro_1aXKh2v0yIWTJtWbDipOcwKLlP1iD8Rl=s64",
      "userId": "12975752177220403005"
     },
     "user_tz": 240
    },
    "id": "IznTPFy8S2hK",
    "outputId": "4b74fa13-defc-4845-b213-422e9e2e00ee"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/pandas/core/generic.py:5170: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self[name] = value\n",
      "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ],
   "source": [
    "train=process_df(train)\n",
    "validation=process_df(validation)\n",
    "test_data=process_df(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "executionInfo": {
     "elapsed": 167,
     "status": "ok",
     "timestamp": 1620393088786,
     "user": {
      "displayName": "Kevin Nguyen",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjO7Ro_1aXKh2v0yIWTJtWbDipOcwKLlP1iD8Rl=s64",
      "userId": "12975752177220403005"
     },
     "user_tz": 240
    },
    "id": "h-OT-WLsK1W_"
   },
   "outputs": [],
   "source": [
    "def find_spans(span_index,text):\n",
    "    '''Function takes in the span index list and returns the text those indices correspond to'''\n",
    "    try:  \n",
    "        span_index=[int(item) for item in span_index]\n",
    "        current_index=span_index[0]\n",
    "        spans=[]\n",
    "        span_text=[]\n",
    "        for i in range(len(span_index)-1):\n",
    "            if span_index[i+1]-span_index[i]>1:\n",
    "                spans.append((current_index,span_index[i]+1))\n",
    "                current_index=span_index[i+1]\n",
    "        if current_index==span_index[0]:\n",
    "            spans.append((current_index,span_index[-1]+1))\n",
    "        return spans\n",
    "    except:\n",
    "        return []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "54cpY4eoX8sD"
   },
   "source": [
    "Implementing SpanBERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "executionInfo": {
     "elapsed": 863,
     "status": "ok",
     "timestamp": 1620393177039,
     "user": {
      "displayName": "Kevin Nguyen",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjO7Ro_1aXKh2v0yIWTJtWbDipOcwKLlP1iD8Rl=s64",
      "userId": "12975752177220403005"
     },
     "user_tz": 240
    },
    "id": "thuD464iYNAq"
   },
   "outputs": [],
   "source": [
    "spanbert_path='spanbert_hf_base/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "executionInfo": {
     "elapsed": 1526,
     "status": "ok",
     "timestamp": 1620393179228,
     "user": {
      "displayName": "Kevin Nguyen",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjO7Ro_1aXKh2v0yIWTJtWbDipOcwKLlP1iD8Rl=s64",
      "userId": "12975752177220403005"
     },
     "user_tz": 240
    },
    "id": "3Gha8oESaih9"
   },
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizerFast.from_pretrained(spanbert_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "executionInfo": {
     "elapsed": 1418,
     "status": "ok",
     "timestamp": 1620393184164,
     "user": {
      "displayName": "Kevin Nguyen",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjO7Ro_1aXKh2v0yIWTJtWbDipOcwKLlP1iD8Rl=s64",
      "userId": "12975752177220403005"
     },
     "user_tz": 240
    },
    "id": "2CaZW4ZPiOi5"
   },
   "outputs": [],
   "source": [
    "class TrainTweetExamples:\n",
    "    def __init__(self,text,sentiment,span_index,max_len,doc_max_len):\n",
    "        self.text=text\n",
    "        self.sentiment=sentiment\n",
    "        self.span_index=span_index\n",
    "        self.character_in_ans=None\n",
    "        self.max_len=max_len\n",
    "        self.doc_max_len=doc_max_len\n",
    "    \n",
    "    def preprocess(self):\n",
    "        text=self.text\n",
    "        sentiment=self.sentiment\n",
    "        span_index=self.span_index\n",
    "\n",
    "        # Mark character indices in text:\n",
    "        character_in_ans=[0]*len(text)\n",
    "        spans=find_spans(span_index,text)\n",
    "        for start,end in spans: # marking the 1s\n",
    "              for idx in range(start,end):\n",
    "                    character_in_ans[idx]=1\n",
    "\n",
    "\n",
    "        # Text tokenization and input prep\n",
    "        tokenized_text = tokenizer.encode_plus(text, return_offsets_mapping=True, max_length = self.max_len)\n",
    "        tokenized_sentiment=tokenizer.encode_plus(sentiment, return_offsets_mapping=True, max_length = self.max_len)\n",
    "        input_ids = tokenized_text.input_ids + tokenized_sentiment.input_ids[1:] # The choice of 1: is to remove the beginning 101.\n",
    "        token_type_ids = [0] * len(tokenized_text.input_ids) + [1] * len(\n",
    "                tokenized_sentiment.input_ids[1:]\n",
    "            )\n",
    "        attention_mask = [1] * len(input_ids)\n",
    "\n",
    "        # Generate the actual tokens:\n",
    "        ans_token_idx = []\n",
    "        for idx, (start, end) in enumerate(tokenized_text.offset_mapping):\n",
    "            if sum(character_in_ans[start:end]) > 0:\n",
    "                ans_token_idx.append([0,1])\n",
    "            else: \n",
    "                ans_token_idx.append([1,0]) # Not toxic\n",
    "\n",
    "        # Padding\n",
    "        padding_length = self.max_len - len(input_ids)\n",
    "        if padding_length > 0: \n",
    "            input_ids = input_ids + ([0] * padding_length)\n",
    "            attention_mask = attention_mask + ([0] * padding_length)\n",
    "            token_type_ids = token_type_ids + ([0] * padding_length)\n",
    "        padding_length_toxic=self.doc_max_len - len(ans_token_idx)\n",
    "        if padding_length_toxic>0:\n",
    "            ans_token_idx=ans_token_idx+[[0,0]]*padding_length_toxic\n",
    "\n",
    "\n",
    "        #Assignments\n",
    "        self.input_ids = input_ids\n",
    "        self.token_type_ids = token_type_ids\n",
    "        self.attention_mask = attention_mask\n",
    "        self.context_token_to_char = tokenized_text.offset_mapping\n",
    "        self.character_in_ans=character_in_ans\n",
    "        self.ans_token_idx = ans_token_idx\n",
    "\n",
    "    def check_length(self):\n",
    "        print(\"Length of tokenized input: \",len(self.tokenized_text.input_ids),\", length of tokenized answers: \",len(self.ans_token_idx))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "executionInfo": {
     "elapsed": 597,
     "status": "ok",
     "timestamp": 1620393188058,
     "user": {
      "displayName": "Kevin Nguyen",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjO7Ro_1aXKh2v0yIWTJtWbDipOcwKLlP1iD8Rl=s64",
      "userId": "12975752177220403005"
     },
     "user_tz": 240
    },
    "id": "LqX4a0DhFpHN"
   },
   "outputs": [],
   "source": [
    "def create_tweet_examples(data,max_len,doc_max_len):\n",
    "    tweet_examples = []\n",
    "    count = 0\n",
    "    for index, row in data.iterrows():\n",
    "        sentiment = row['sentiment']\n",
    "        text = row['text']\n",
    "        span_index=row['spans']\n",
    "        ## turn the data into TrainTweetExample objects\n",
    "        try:\n",
    "            tweet_eg = TrainTweetExamples(text, sentiment, span_index,max_len,doc_max_len)\n",
    "            tweet_eg.preprocess()\n",
    "            tweet_examples.append(tweet_eg)\n",
    "        except: ## keep track of the number that can't be tokenized/processed\n",
    "            count += 1 \n",
    "    print(\"Couldn't process\",count,\"points\")\n",
    "    return tweet_examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "executionInfo": {
     "elapsed": 136,
     "status": "ok",
     "timestamp": 1620393190393,
     "user": {
      "displayName": "Kevin Nguyen",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjO7Ro_1aXKh2v0yIWTJtWbDipOcwKLlP1iD8Rl=s64",
      "userId": "12975752177220403005"
     },
     "user_tz": 240
    },
    "id": "wHFCUBS_HBp8"
   },
   "outputs": [],
   "source": [
    "def create_inputs_targets(tweet_examples):\n",
    "    dataset_dict = {\n",
    "        \"input_ids\": [],\n",
    "        \"token_type_ids\": [],\n",
    "        \"attention_mask\": [],\n",
    "        \"ans_token_idx\":[]\n",
    "    }\n",
    "    for item in tweet_examples:\n",
    "        #if item.skip == False:\n",
    "        for key in dataset_dict.keys():\n",
    "              dataset_dict[key].append(getattr(item, key))\n",
    "\n",
    "    x = [\n",
    "        np.array(dataset_dict[\"input_ids\"]),\n",
    "        np.array(dataset_dict[\"token_type_ids\"]),\n",
    "        np.array(dataset_dict[\"attention_mask\"])]\n",
    "    y = np.array(dataset_dict[\"ans_token_idx\"])\n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 13481,
     "status": "ok",
     "timestamp": 1620393206556,
     "user": {
      "displayName": "Kevin Nguyen",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjO7Ro_1aXKh2v0yIWTJtWbDipOcwKLlP1iD8Rl=s64",
      "userId": "12975752177220403005"
     },
     "user_tz": 240
    },
    "id": "Ywn8yrLtLwJN",
    "outputId": "60829427-33c2-48a5-8580-e57570ffabb6"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Couldn't process 0 points\n",
      "Couldn't process 0 points\n",
      "Couldn't process 0 points\n"
     ]
    }
   ],
   "source": [
    "train_tweet_examples = create_tweet_examples(train,max_len,doc_max_len)\n",
    "x_train, y_train = create_inputs_targets(train_tweet_examples)\n",
    "val_tweet_examples = create_tweet_examples(validation,max_len,doc_max_len)\n",
    "x_val, y_val = create_inputs_targets(val_tweet_examples)\n",
    "test_tweet_examples = create_tweet_examples(test_data,max_len,doc_max_len)\n",
    "x_test, y_test = create_inputs_targets(test_tweet_examples)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tdhS02meMYJy"
   },
   "source": [
    "Creating the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "executionInfo": {
     "elapsed": 230,
     "status": "ok",
     "timestamp": 1620393209834,
     "user": {
      "displayName": "Kevin Nguyen",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjO7Ro_1aXKh2v0yIWTJtWbDipOcwKLlP1iD8Rl=s64",
      "userId": "12975752177220403005"
     },
     "user_tz": 240
    },
    "id": "-9ZnjwEWMd_q"
   },
   "outputs": [],
   "source": [
    "def create_model(max_len,doc_max_len):\n",
    "    encoder = TFBertModel.from_pretrained(spanbert_path,from_pt=True)\n",
    "    input_ids = layers.Input(shape=(max_len ,), dtype=tf.int32)\n",
    "    token_type_ids = layers.Input(shape=(max_len,), dtype=tf.int32)\n",
    "    attention_mask = layers.Input(shape=(max_len,), dtype=tf.int32)\n",
    "    start_logits = encoder(\n",
    "             input_ids, token_type_ids=token_type_ids, attention_mask=attention_mask\n",
    "        )[0]\n",
    "    #start_logits=layers.Bidirectional(layers.GRU(256,return_sequence=True))(start_logits)\n",
    "    #start_logits=layers.Conv1D(128,2,padding=\"same\")(start_logits)\n",
    "    start_logits=layers.Dropout(0.2)(start_logits)\n",
    "    start_logits=layers.TimeDistributed(layers.Dense(2,activation=\"softmax\"))(start_logits)\n",
    "    model=Model([input_ids,token_type_ids,attention_mask],start_logits)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 55440,
     "status": "ok",
     "timestamp": 1620393268830,
     "user": {
      "displayName": "Kevin Nguyen",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjO7Ro_1aXKh2v0yIWTJtWbDipOcwKLlP1iD8Rl=s64",
      "userId": "12975752177220403005"
     },
     "user_tz": 240
    },
    "id": "8cBfVPHTNrNp",
    "outputId": "f6cf3e32-a503-450e-e204-bbd9cddc9a4f"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All PyTorch model weights were used when initializing TFBertModel.\n",
      "\n",
      "Some weights or buffers of the TF 2.0 model TFBertModel were not initialized from the PyTorch model and are newly initialized: ['bert.pooler.dense.weight', 'bert.pooler.dense.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "WARNING:tensorflow:AutoGraph could not transform <bound method Socket.send of <zmq.sugar.socket.Socket object at 0x7f63353b2d00>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module, class, method, function, traceback, frame, or code object was expected, got cython_function_or_method\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <bound method Socket.send of <zmq.sugar.socket.Socket object at 0x7f63353b2d00>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module, class, method, function, traceback, frame, or code object was expected, got cython_function_or_method\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function wrap at 0x7f6350c5ed40> and will run it as-is.\n",
      "Cause: while/else statement not yet supported\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function wrap at 0x7f6350c5ed40> and will run it as-is.\n",
      "Cause: while/else statement not yet supported\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
     ]
    }
   ],
   "source": [
    "use_tpu = False\n",
    "if use_tpu:\n",
    "    # Create distribution strategy\n",
    "    tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n",
    "    tf.config.experimental_connect_to_cluster(tpu)\n",
    "    tf.tpu.experimental.initialize_tpu_system(tpu)\n",
    "    strategy = tf.distribute.TPUStrategy(tpu)\n",
    "\n",
    "    # Create model\n",
    "    with strategy.scope():\n",
    "        model = create_model(max_len,doc_max_len)\n",
    "else:\n",
    "    model = create_model(max_len,doc_max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "executionInfo": {
     "elapsed": 277,
     "status": "ok",
     "timestamp": 1620393283670,
     "user": {
      "displayName": "Kevin Nguyen",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjO7Ro_1aXKh2v0yIWTJtWbDipOcwKLlP1iD8Rl=s64",
      "userId": "12975752177220403005"
     },
     "user_tz": 240
    },
    "id": "ssSIeBZtOMDY"
   },
   "outputs": [],
   "source": [
    "optimizer = keras.optimizers.Adam(lr=5e-5)\n",
    "model.compile(optimizer=optimizer,loss=\"categorical_crossentropy\",metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "executionInfo": {
     "elapsed": 985,
     "status": "ok",
     "timestamp": 1620393285602,
     "user": {
      "displayName": "Kevin Nguyen",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjO7Ro_1aXKh2v0yIWTJtWbDipOcwKLlP1iD8Rl=s64",
      "userId": "12975752177220403005"
     },
     "user_tz": 240
    },
    "id": "AxeZNy9rm2uB"
   },
   "outputs": [],
   "source": [
    "early_stop=EarlyStopping(monitor=\"val_accuracy\",patience=3,restore_best_weights=True)\n",
    "model_checkpoint=ModelCheckpoint(filepath=\"NN_SpanBERT_TC\",monitor=\"val_accuracy\",save_best_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 2317623,
     "status": "error",
     "timestamp": 1620395673957,
     "user": {
      "displayName": "Kevin Nguyen",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjO7Ro_1aXKh2v0yIWTJtWbDipOcwKLlP1iD8Rl=s64",
      "userId": "12975752177220403005"
     },
     "user_tz": 240
    },
    "id": "KBhmyktqP9gH",
    "outputId": "17771483-797f-4730-ffbc-100a844e4e9a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "804/804 [==============================] - ETA: 0s - loss: 0.0259 - accuracy: 0.9913WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "804/804 [==============================] - 1124s 1s/step - loss: 0.0259 - accuracy: 0.9913 - val_loss: 0.0214 - val_accuracy: 0.9937\n",
      "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as embeddings_layer_call_and_return_conditional_losses, embeddings_layer_call_fn, encoder_layer_call_and_return_conditional_losses, encoder_layer_call_fn, pooler_layer_call_and_return_conditional_losses while saving (showing 5 of 1055). These functions will not be directly callable after loading.\n",
      "WARNING:absl:Found untraced functions such as embeddings_layer_call_and_return_conditional_losses, embeddings_layer_call_fn, encoder_layer_call_and_return_conditional_losses, encoder_layer_call_fn, pooler_layer_call_and_return_conditional_losses while saving (showing 5 of 1055). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /content/drive/MyDrive/Span NN materials/NN_SpanBERT_TC/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /content/drive/MyDrive/Span NN materials/NN_SpanBERT_TC/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/3\n",
      "804/804 [==============================] - 1119s 1s/step - loss: 0.0227 - accuracy: 0.9925 - val_loss: 0.0206 - val_accuracy: 0.9937\n",
      "Epoch 3/3\n",
      "  7/804 [..............................] - ETA: 17:47 - loss: 0.0299 - accuracy: 0.9878"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-22-9ab61e38cee6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvalidation_split\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mearly_stop\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmodel_checkpoint\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1103\u001b[0m               \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtmp_logs\u001b[0m  \u001b[0;31m# No error, now safe to assign to logs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m               \u001b[0mend_step\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep_increment\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1105\u001b[0;31m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mend_step\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1106\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_training\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1107\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/callbacks.py\u001b[0m in \u001b[0;36mon_train_batch_end\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m    452\u001b[0m     \"\"\"\n\u001b[1;32m    453\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_should_call_train_batch_hooks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 454\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'end'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    455\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mon_test_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/callbacks.py\u001b[0m in \u001b[0;36m_call_batch_hook\u001b[0;34m(self, mode, hook, batch, logs)\u001b[0m\n\u001b[1;32m    294\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_begin_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    295\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'end'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 296\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_end_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    297\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    298\u001b[0m       \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Unrecognized hook: {}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/callbacks.py\u001b[0m in \u001b[0;36m_call_batch_end_hook\u001b[0;34m(self, mode, batch, logs)\u001b[0m\n\u001b[1;32m    314\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_batch_times\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_time\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    315\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 316\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_hook_helper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhook_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    317\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    318\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_batch_times\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_batches_for_timing_check\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/callbacks.py\u001b[0m in \u001b[0;36m_call_batch_hook_helper\u001b[0;34m(self, hook_name, batch, logs)\u001b[0m\n\u001b[1;32m    354\u001b[0m       \u001b[0mhook\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcallback\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    355\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcallback\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'_supports_tf_logs'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 356\u001b[0;31m         \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    357\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    358\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mnumpy_logs\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# Only convert once.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/callbacks.py\u001b[0m in \u001b[0;36mon_train_batch_end\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m   1018\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1019\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mon_train_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1020\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_batch_update_progbar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1021\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1022\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mon_test_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/callbacks.py\u001b[0m in \u001b[0;36m_batch_update_progbar\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m   1082\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverbose\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1083\u001b[0m       \u001b[0;31m# Only block async when verbose = 1.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1084\u001b[0;31m       \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_numpy_or_python_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1085\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprogbar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfinalize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1086\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/utils/tf_utils.py\u001b[0m in \u001b[0;36mto_numpy_or_python_type\u001b[0;34m(tensors)\u001b[0m\n\u001b[1;32m    512\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m  \u001b[0;31m# Don't turn ragged or sparse tensors to NumPy.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    513\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 514\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_structure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_to_single_numpy_or_python_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    515\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    516\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/nest.py\u001b[0m in \u001b[0;36mmap_structure\u001b[0;34m(func, *structure, **kwargs)\u001b[0m\n\u001b[1;32m    657\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    658\u001b[0m   return pack_sequence_as(\n\u001b[0;32m--> 659\u001b[0;31m       \u001b[0mstructure\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    660\u001b[0m       expand_composites=expand_composites)\n\u001b[1;32m    661\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/nest.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    657\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    658\u001b[0m   return pack_sequence_as(\n\u001b[0;32m--> 659\u001b[0;31m       \u001b[0mstructure\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    660\u001b[0m       expand_composites=expand_composites)\n\u001b[1;32m    661\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/utils/tf_utils.py\u001b[0m in \u001b[0;36m_to_single_numpy_or_python_type\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m    508\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_to_single_numpy_or_python_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    509\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 510\u001b[0;31m       \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    511\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    512\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m  \u001b[0;31m# Don't turn ragged or sparse tensors to NumPy.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mnumpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1069\u001b[0m     \"\"\"\n\u001b[1;32m   1070\u001b[0m     \u001b[0;31m# TODO(slebedev): Consider avoiding a copy for non-CPU or remote tensors.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1071\u001b[0;31m     \u001b[0mmaybe_arr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1072\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mmaybe_arr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmaybe_arr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mmaybe_arr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1073\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_numpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1035\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1036\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1037\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_numpy_internal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1038\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1039\u001b[0m       \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model.fit(x_train,y_train,epochs=3,batch_size=8,validation_split=0.10,callbacks=[early_stop,model_checkpoint])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "t3GZ0ItBVWmE"
   },
   "source": [
    "Predicting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "executionInfo": {
     "elapsed": 283,
     "status": "ok",
     "timestamp": 1620395680233,
     "user": {
      "displayName": "Kevin Nguyen",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjO7Ro_1aXKh2v0yIWTJtWbDipOcwKLlP1iD8Rl=s64",
      "userId": "12975752177220403005"
     },
     "user_tz": 240
    },
    "id": "NgyEsmK3YduG"
   },
   "outputs": [],
   "source": [
    "def get_indices(x):\n",
    "    indice_prediction=[]\n",
    "    for single_prediction in x:\n",
    "        indice_prediction.append([idx for idx,value in enumerate(single_prediction) if value[1]>=0.5])\n",
    "        return indice_prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "executionInfo": {
     "elapsed": 195,
     "status": "ok",
     "timestamp": 1620395681303,
     "user": {
      "displayName": "Kevin Nguyen",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjO7Ro_1aXKh2v0yIWTJtWbDipOcwKLlP1iD8Rl=s64",
      "userId": "12975752177220403005"
     },
     "user_tz": 240
    },
    "id": "QAIY5lNfZsFW"
   },
   "outputs": [],
   "source": [
    "def get_indices_final(indice_prediction,tweet_examples):\n",
    "    all_correct_indices=[]\n",
    "    for i in range(len(indice_prediction)):\n",
    "    correct_indices=[]\n",
    "    indices=indice_prediction[i]\n",
    "    tweet=tweet_examples[i].context_token_to_char\n",
    "    for i in indices:\n",
    "        if i <len(tweet):\n",
    "            start,end=tweet[i]\n",
    "            correct_indices.extend([index for index in range(start,end)])\n",
    "    all_correct_indices.append(correct_indices)\n",
    "    return all_correct_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "executionInfo": {
     "elapsed": 267,
     "status": "ok",
     "timestamp": 1620395684480,
     "user": {
      "displayName": "Kevin Nguyen",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjO7Ro_1aXKh2v0yIWTJtWbDipOcwKLlP1iD8Rl=s64",
      "userId": "12975752177220403005"
     },
     "user_tz": 240
    },
    "id": "LdTAOqey3S-U"
   },
   "outputs": [],
   "source": [
    "def convert_to_indices(input_data,tweet_examples):\n",
    "    global model\n",
    "    predictions=model.predict(input_data)\n",
    "    indice_prediction=get_indices(predictions)\n",
    "    final_indices=get_indices_final(indice_prediction,tweet_examples)\n",
    "    return final_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "executionInfo": {
     "elapsed": 233,
     "status": "ok",
     "timestamp": 1620395685760,
     "user": {
      "displayName": "Kevin Nguyen",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjO7Ro_1aXKh2v0yIWTJtWbDipOcwKLlP1iD8Rl=s64",
      "userId": "12975752177220403005"
     },
     "user_tz": 240
    },
    "id": "9Ti8u0F9otU7"
   },
   "outputs": [],
   "source": [
    "def f1(predictions, gold):\n",
    "    \"\"\"\n",
    "    F1 (a.k.a. DICE) operating on two lists of offsets (e.g., character).\n",
    "    >>> assert f1([0, 1, 4, 5], [0, 1, 6]) == 0.5714285714285714\n",
    "    :param predictions: a list of predicted offsets\n",
    "    :param gold: a list of offsets serving as the ground truth\n",
    "    :return: a score between 0 and 1\n",
    "    \"\"\"\n",
    "    if len(gold) == 0:\n",
    "        return 1. if len(predictions) == 0 else 0.\n",
    "    if len(predictions) == 0:\n",
    "        return 0.\n",
    "    predictions_set = set(predictions)\n",
    "    gold_set = set(gold)\n",
    "    nom = 2 * len(predictions_set.intersection(gold_set))\n",
    "    denom = len(predictions_set) + len(gold_set)\n",
    "    return float(nom)/float(denom)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "executionInfo": {
     "elapsed": 684,
     "status": "ok",
     "timestamp": 1620395688505,
     "user": {
      "displayName": "Kevin Nguyen",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjO7Ro_1aXKh2v0yIWTJtWbDipOcwKLlP1iD8Rl=s64",
      "userId": "12975752177220403005"
     },
     "user_tz": 240
    },
    "id": "OPIJP0fbrdoA"
   },
   "outputs": [],
   "source": [
    "def all_f1_scores(predictions,golds):\n",
    "    f1_scores=[]\n",
    "    for i in range(len(predictions)):\n",
    "        f1_score=f1(predictions[i],golds.spans.values[i])\n",
    "        f1_scores.append(f1_score)\n",
    "    return f1_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 159439,
     "status": "ok",
     "timestamp": 1620395848143,
     "user": {
      "displayName": "Kevin Nguyen",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjO7Ro_1aXKh2v0yIWTJtWbDipOcwKLlP1iD8Rl=s64",
      "userId": "12975752177220403005"
     },
     "user_tz": 240
    },
    "id": "u1aCuRrAsBzF",
    "outputId": "7b456253-eb1b-49af-ee5b-3a7434954773"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
     ]
    }
   ],
   "source": [
    "indices_val=convert_to_indices(x_val,val_tweet_examples)\n",
    "f1_val=all_f1_scores(indices_val,validation)\n",
    "indices_test=convert_to_indices(x_test,test_tweet_examples)\n",
    "f1_test=all_f1_scores(indices_test,test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "executionInfo": {
     "elapsed": 153439,
     "status": "ok",
     "timestamp": 1620395848150,
     "user": {
      "displayName": "Kevin Nguyen",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjO7Ro_1aXKh2v0yIWTJtWbDipOcwKLlP1iD8Rl=s64",
      "userId": "12975752177220403005"
     },
     "user_tz": 240
    },
    "id": "owVcyGWQEkQS"
   },
   "outputs": [],
   "source": [
    "df_val=pd.DataFrame({\"span\":indices_val,\"text\":validation.text.values})\n",
    "df_test=pd.DataFrame({\"span\":indices_test,\"text\":test_data.text.values})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "executionInfo": {
     "elapsed": 153162,
     "status": "ok",
     "timestamp": 1620395848662,
     "user": {
      "displayName": "Kevin Nguyen",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjO7Ro_1aXKh2v0yIWTJtWbDipOcwKLlP1iD8Rl=s64",
      "userId": "12975752177220403005"
     },
     "user_tz": 240
    },
    "id": "XyWxPfGIGHXC"
   },
   "outputs": [],
   "source": [
    "df_val.to_csv(\"Spanbert_TC_validation.csv\")\n",
    "df_test.to_csv(\"Spanbert_TC_test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 224,
     "status": "ok",
     "timestamp": 1620395946300,
     "user": {
      "displayName": "Kevin Nguyen",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjO7Ro_1aXKh2v0yIWTJtWbDipOcwKLlP1iD8Rl=s64",
      "userId": "12975752177220403005"
     },
     "user_tz": 240
    },
    "id": "qnktO7jkH74p",
    "outputId": "86e96cba-aed1-459d-fa32-f1899ca9e032"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.842483931123918"
      ]
     },
     "execution_count": 32,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "Token Classification script.ipynb",
   "provenance": [
    {
     "file_id": "1dycxMLG4voKGY4YFAd_HjpBaF6UQLMrw",
     "timestamp": 1620276185157
    }
   ]
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
